### <level 1>

## machine learning 

# Code you have previously used to load data

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
#from learntools.core import *

# Path of the file to read. 

iowa_file_path = 'iowa_train.csv'

home_data = pd.read_csv(iowa_file_path)

# Create target object and call it y

y = home_data.SalePrice

# Create X

features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 
            'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']

X = home_data[features]

# Split into validation and training data

train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)

# Specify Model

iowa_model = DecisionTreeRegressor(random_state=1)

# Fit Model

iowa_model.fit(train_X, train_y)

# Make validation predictions and calculate mean absolute error

val_predictions = iowa_model.predict(val_X)

val_mae = mean_absolute_error(val_predictions, val_y)

print("Validation MAE when not specifying max_leaf_nodes: {:,.0f}".format(val_mae))

# Using best value for max_leaf_nodes

iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)

iowa_model.fit(train_X, train_y)

val_predictions = iowa_model.predict(val_X)

val_mae = mean_absolute_error(val_predictions, val_y)

print("Validation MAE for best value of max_leaf_nodes: {:,.0f}".
      format(val_mae))

# Define the model. Set random_state to 1

rf_model = RandomForestRegressor(random_state=1)

rf_model.fit(train_X, train_y)

rf_val_predictions = rf_model.predict(val_X)

rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)

print("Validation MAE for Random Forest Model: {:,.0f}".
      format(rf_val_mae))

# To improve accuracy, create a new Random Forest model which you will train on all training data

rf_model_on_full_data = RandomForestRegressor(random_state = 1)

# fit rf_model_on_full_data on all data from the training data

rf_model_on_full_data.fit(train_X, train_y)

# path to file you will use for predictions

test_data_path = 'iowa_test.csv'

# read test data file using pandas

test_data = pd.read_csv(test_data_path)

# create test_X which comes from test_data but includes only the columns you used for prediction.

# The list of columns is stored in a variable called features

test_X = test_data[features]

# make predictions which we will submit. 

test_preds = rf_model_on_full_data.predict(test_X)

# The lines below shows how to save predictions in format

output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_preds})

output.to_csv('submission.csv', index=False)

### <level 2> 

## 1) handling missing values 

# solution 1 - dropping columns with missing values 

import pandas as pd

# Load data

melb_data = pd.read_csv('melb_data.csv')

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

melb_target = melb_data.Price

melb_predictors = melb_data.drop(['Price'], axis=1)

# use only numeric predictors. 
melb_num_predictors = melb_predictors.select_dtypes(exclude=['object'])

# split into training and test set 

X_train, X_test, y_train, y_test = train_test_split(melb_num_predictors, 
                                                    melb_target,
                                                    train_size=0.7, 
                                                    test_size=0.3, 
                                                    random_state=0)

def score_dataset(X_train, X_test, y_train, y_test):
    model = RandomForestRegressor()
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    return mean_absolute_error(y_test, preds)

# get model score from dropping columns with missing values 

cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]

reduced_X_train = X_train.drop(cols_with_missing, axis = 1) 

reduced_X_test = X_test.drop(cols_with_missing, axis = 1) 

print("Mean Absolute Error from dropping columns with Missing Values:") 
print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))

## solution 2 - imputation 

from sklearn.impute import SimpleImputer 

my_imputer = Imputer() 

imputed_X_train = my_imputer.fit_transform(X_train)

imputed_X_test = my_imputer.fit_transform(X_test)

print("Mean Absolute Error from Imputation:")
print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))

## solution 3 - extension to imputation: 

# make a copy of original 

imputed_X_train_plus = X_train.copy()

imputed_X_test_plus = X_test.copy()

cols_with_missing = [col for col in X_train.columns
if X_train[col].isnull().any()]

for col in cols_with_missing: 
    imputed_X_train_plus[col + '_was missing'] = imputed_X_train_plus[col].isnull()
    imputed_X_test_plus[col + '_was missing'] = imputed_X_test_plus[col].isnull() 

# imputation

my_imputer = Imputer() 

imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus) 

imputed_X_test_plus = my_imputer.fit_transform(imputed_X_test_plus)

print("Mean Absolute Error from Imputation while Track What Was Imputed:")
print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))


## 2) categorical variable 

# without encoding categorical variables, an error occurs 
# how to encode categorical variables 

# one hot encoding 

import pandas as pd 

train_data = pd.read_csv('iowa_train.csv')

test_data = pd.read_csv('iowa_test.csv')

train_data.describe()

# drop houses where the target is missing 

train_data.dropna(axis = 0, subset = ['SalePrice'], inplace = True)

target = train_data.SalePrice

cols_with_missing = [col for col in train_data.columns 
if train_data[col].isnull().any()]

train_predictors = train_data.drop(['Id', 'SalePrice'] + cols_with_missing, axis = 1) 

test_predictors = test_data.drop(['Id'] + cols_with_missing, axis = 1)

# select categorical columns 

low_cardinality_cols = [cname for cname in train_predictors.columns if 
                                train_predictors[cname].nunique() < 10 and
                                train_predictors[cname].dtype == "object"]

num_cols = [cname for cname in train_predictors.columns 
if train_predictors[cname].dtype in ['int64', 'float64']]

my_cols = low_cardinality_cols + num_cols 

train_predictors = train_predictors[my_cols]

test_predictors = test_predictors[my_cols]

train_predictors.dtypes.sample(10)

# Object indicates a column has text 
# pandas offers a function called get_dummies to get one hot encodings 

one_hot_encoded_training_predcitors = pd.get_dummies(train_predictors)

# drop categorical variables 

# compare these 2 approaches using MAE: dropping categorical / one hot encoded categorical 

from sklearn.model_selection import cross_val_score

from sklearn.ensemble import RandomForestRegressor

def get_mae(X, y): 
      return -1 * cross_val_score(RandomForestRegressor(50), 
      X, y, 
      scoring = 'neg_mean_absolute_error').mean() 
      # multiply by -1 to cross validation score to make positive MAE score 

predictors_wo_categoricals = train_predictors.select_dtypes(exclude = ['object'])

mae_wo_categoricals = get_mae(predictors_wo_categoricals, target)

mae_one_hot_encoded = get_mae(one_hot_encoded_training_predcitors, target)


print('Mean Absolute Error when Dropping Categoricals: ' + str(int(mae_wo_categoricals)))
print('Mean Abslute Error with One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))

# applying to multiple files; make sure to align with test predictors 
# align makes sure columns show up in the same order  

one_hot_encoded_training_predcitors = pd.get_dummies(train_predictors)

one_hot_encoded_test_predictors = pd.get_dummies(test_predictors)

final_train, final_test = one_hot_encoded_training_predcitors.align(one_hot_encoded_test_predictors, 
join = 'left', axis = 1)


## 3) pipelines 
## the way to keep data preprocessing and modeling code organised. 
## benefits: cleaner code / fewer bugs / easier to productionalise / more options for model validation 

import pandas as pd 
from sklearn.model_selection import train_test_split 

pipe_data = pd.read_csv('melb_data.csv')

y = pipe_data.Price 
X = pipe_data.drop(['Price'], axis = 1 )

X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 0)

# Cardinality : meaning the number of unique values in a column 
# select categorical columns with relatively low cardinality 

categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype == 'object']

# select numerical columns 

numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]

# keep selected columns only 

my_cols = categorical_cols + numerical_cols
X_train = X_train_full[my_cols].copy() 
X_valid = X_valid_full[my_cols].copy()

X_train.head()

## constructing pipelines in 3 steps 
      # step 1: define preprocessing steps 

from sklearn.compose import ColumnTransformer 
from sklearn.pipeline import Pipeline 
from sklearn.impute import SimpleImputer 
from sklearn.preprocessing import OneHotEncoder

# preprocessing numerical data 

numerical_transformer = SimpleImputer(strategy = 'constant')

# preprocessing categorical data 

categorical_transformer = Pipeline(steps = [
      ('imputer', SimpleImputer(strategy = 'most_frequent')), 
      ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# bundle preprocessing for numerical, categorical data 

preprocessor = ColumnTransformer(
      transformers = [
            ('num', numerical_transformer, numerical_cols), 
            ('cat', categorical_transformer, categorical_cols)
      ]
)

      # step 2: define the model 

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=0)

      # step 3: create and evaluate the pipeline 
# using Pipeline class to define a pipeline that bundles the preprocessing and modeling steps 

#With the pipeline, we preprocess the training data and fit the model in a single line of code. 
# (In contrast, without a pipeline, we have to do imputation, one-hot encoding, 
# and model training in separate steps. This becomes especially messy 
# if we have to deal with both numerical and categorical variables!)

from sklearn.metrics import mean_absolute_error

# bundle preprocessing and modeling code in a pipeline 

my_pipeline = Pipeline(steps = [('preprocessor', preprocessor), 
('model', model)])

# preprocessing of training data and model 

my_pipeline.fit(X_train, y_train)

# preprocessing of validation data, get predictions 

preds = my_pipeline.predict(X_valid)

# evaluate the model 

score = mean_absolute_error(y_valid, preds)

print('MAE:', score)


## 4) cross-validation: 
## the larger the validation set, the less randomness there is in measure of model quality. 
## cross validation : run modeling process on different subsets of data to get multiple measures of model quality 
## for smaller datasets cross validation should be run; for larger datasets a single validation set is sufficient.

import pandas as pd 

data = pd.read_csv('melb_data.csv')

# select subset of predictors 

cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']
X = data[cols_to_use]

# select target 

y = data.Price

# define pipeline that uses imputer to fill in missing values 
# random forest to make predictions 

from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline 
from sklearn.impute import SingleImputer

# n_estimators : set the number of trees in the RF model 
# random_state : reproducibility 

my_pipeline = Pipeline(steps=[('preprocessor', Imputer()),
                              ('model', RandomForestRegressor(n_estimators=50,
                                                              random_state=0))
                             ])

# We obtain the cross-validation scores with the cross_val_score() function from scikit-learn. 
# We set the number of folds with the cv parameter.

from sklearn.model_selection import cross_val_score 

# multiply by -1 since sklearn calculates negative MAE 
# CV = 5: number of folds 

scores = -1 * cross_val_score(my_pipeline, X, y, cv = 5, scoring = 'neg_mean_absolute_error')

print("MAE scores :\n", scores)

# take the average across experiments 

print("Average MAE score (across experiments): ") 
print(scores.mean())


# exercise: write a function 

def get_score(n_estimators): 
      my_pipeline = Pipeline(steps = [
            ('preprocessor', Imputer()), 
            ('model', RandomForestRegressor(n_estimators, random_state = 0))
      ])
      scores = -1 * cross_val_score(my_pipeline, 
      X, y, cv = 3, 
      scoring = 'neg_mean_absolute_error')
      return scores.mean 

# exercise 2 : experiment different parameter values from 50, 150, 200 ... 400 

results = {}
for i in range(1,9): 
      results[50*i] = get_score(50*i) 

# exercise 3 : visualise the best parameter      

import matplotlib.pyplot as plt 

# matplotlib inline

plt.plot(results.keys(), results.values())
plt.show()

# from the plot what is the best parameter?

n_estimators_best = min(results, key = results.get)

print(n_estimators_best)




## 6) XG Boost : an implementation of the gradient boosted decision trees algorithm 
## cycles, that repeatedly builds new models and combines them into new ensemble model / 
## we start the cycle by calculating the errors for each observation in the dataset, then build  a new model to predict those, 
## add predictions from error-predicting model to 'ensemble of models' 
# To make a prediction, we add the predictions from all previous models. 
# We can use these predictions to calculate new errors, build the next model, 
# and add it to the ensemble. 

import pandas as pd 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import Imputer 

boost_data = pd.read_csv('boost_train.csv')

boost_data.describe()

boost_data.dropna(axis = 0, subset = ['SalePrice'], inplace = True)

y = boost_data.SalePrice

X = boost_data.drop(['SalePrice'], axis = 1).select_dtypes(exclude = ['object'])

train_X, test_X, train_y, test_y = train_test_split(X.as_matrix(), y.as_matrix(), test_size = 0.25)

my_imputer = Imputer()

train_X = my_imputer.fit_transform(train_X)

test_X = my_imputer.fit_transform(test_X)

# building a model 

from xgboost import XGBRegressor

#from xgboost import XGBRegressor

my_model = XGBRegressor()

# add silent = true to avoid printing out updates with each cycle 

my_model.fit(train_X, train_y, verbose = False)


