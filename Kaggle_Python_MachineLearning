### <level 1>

## machine learning 

# Code you have previously used to load data

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
#from learntools.core import *

# Path of the file to read. 

iowa_file_path = 'iowa_train.csv'

home_data = pd.read_csv(iowa_file_path)

# Create target object and call it y

y = home_data.SalePrice

# Create X

features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 
            'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']

X = home_data[features]

# Split into validation and training data

train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)

# Specify Model

iowa_model = DecisionTreeRegressor(random_state=1)

# Fit Model

iowa_model.fit(train_X, train_y)

# Make validation predictions and calculate mean absolute error

val_predictions = iowa_model.predict(val_X)

val_mae = mean_absolute_error(val_predictions, val_y)

print("Validation MAE when not specifying max_leaf_nodes: {:,.0f}".format(val_mae))

# Using best value for max_leaf_nodes

iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)

iowa_model.fit(train_X, train_y)

val_predictions = iowa_model.predict(val_X)

val_mae = mean_absolute_error(val_predictions, val_y)

print("Validation MAE for best value of max_leaf_nodes: {:,.0f}".
      format(val_mae))

# Define the model. Set random_state to 1

rf_model = RandomForestRegressor(random_state=1)

rf_model.fit(train_X, train_y)

rf_val_predictions = rf_model.predict(val_X)

rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)

print("Validation MAE for Random Forest Model: {:,.0f}".
      format(rf_val_mae))

# To improve accuracy, create a new Random Forest model which you will train on all training data

rf_model_on_full_data = RandomForestRegressor(random_state = 1)

# fit rf_model_on_full_data on all data from the training data

rf_model_on_full_data.fit(train_X, train_y)

# path to file you will use for predictions

test_data_path = 'iowa_test.csv'

# read test data file using pandas

test_data = pd.read_csv(test_data_path)

# create test_X which comes from test_data but includes only the columns you used for prediction.

# The list of columns is stored in a variable called features

test_X = test_data[features]

# make predictions which we will submit. 

test_preds = rf_model_on_full_data.predict(test_X)

# The lines below shows how to save predictions in format

output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_preds})

output.to_csv('submission.csv', index=False)

### <level 2> 

## 1) handling missing values 

# solution 1 - dropping columns with missing values 

import pandas as pd

# Load data

melb_data = pd.read_csv('melb_data.csv')

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

melb_target = melb_data.Price

melb_predictors = melb_data.drop(['Price'], axis=1)

# use only numeric predictors. 
melb_num_predictors = melb_predictors.select_dtypes(exclude=['object'])

# split into training and test set 

X_train, X_test, y_train, y_test = train_test_split(melb_num_predictors, 
                                                    melb_target,
                                                    train_size=0.7, 
                                                    test_size=0.3, 
                                                    random_state=0)

def score_dataset(X_train, X_test, y_train, y_test):
    model = RandomForestRegressor()
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    return mean_absolute_error(y_test, preds)

# get model score from dropping columns with missing values 

cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]

reduced_X_train = X_train.drop(cols_with_missing, axis = 1) 

reduced_X_test = X_test.drop(cols_with_missing, axis = 1) 

print("Mean Absolute Error from dropping columns with Missing Values:") 
print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))

## solution 2 - imputation 

from sklearn.impute import SimpleImputer

my_imputer = SimpleImputer() 

imputed_X_train = my_imputer.fit_transform(X_train)

imputed_X_test = my_imputer.fit_transform(X_test)

print("Mean Absolute Error from Imputation:")
print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))

## solution 3 - extension to imputation: 

# make a copy of original 

imputed_X_train_plus = X_train.copy()

imputed_X_test_plus = X_test.copy()

cols_with_missing = [col for col in X_train.columns
if X_train[col].isnull().any()]

for col in cols_with_missing: 
    imputed_X_train_plus[col + '_was missing'] = imputed_X_train_plus[col].isnull()
    imputed_X_test_plus[col + '_was missing'] = imputed_X_test_plus[col].isnull() 

# imputation

my_imputer = SimpleImputer() 

imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus) 

imputed_X_test_plus = my_imputer.fit_transform(imputed_X_test_plus)

print("Mean Absolute Error from Imputation while Track What Was Imputed:")
print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))


## 2) categorical variable 

# without encoding categorical variables, an error occurs 
# how to encode categorical variables 

# one hot encoding 

import pandas as pd 

train_data = pd.read_csv('iowa_train.csv')

test_data = pd.read_csv('iowa_test.csv')

train_data.describe()

# drop houses where the target is missing 

train_data.dropna(axis = 0, subset = ['SalePrice'], inplace = True)

target = train_data.SalePrice

cols_with_missing = [col for col in train_data.columns 
if train_data[col].isnull().any()]

train_predictors = train_data.drop(['Id', 'SalePrice'] + cols_with_missing, axis = 1) 

test_predictors = test_data.drop(['Id'] + cols_with_missing, axis = 1)

# select categorical columns 

low_cardinality_cols = [cname for cname in train_predictors.columns if 
                                train_predictors[cname].nunique() < 10 and
                                train_predictors[cname].dtype == "object"]

num_cols = [cname for cname in train_predictors.columns 
if train_predictors[cname].dtype in ['int64', 'float64']]

my_cols = low_cardinality_cols + num_cols 

train_predictors = train_predictors[my_cols]

test_predictors = test_predictors[my_cols]

train_predictors.dtypes.sample(10)

# Object indicates a column has text 
# pandas offers a function called get_dummies to get one hot encodings 

one_hot_encoded_training_predcitors = pd.get_dummies(train_predictors)

# drop categorical variables 

# compare these 2 approaches using MAE: dropping categorical / one hot encoded categorical 

from sklearn.model_selection import cross_val_score

from sklearn.ensemble import RandomForestRegressor

def get_mae(X, y): 
      return -1 * cross_val_score(RandomForestRegressor(50), 
      X, y, 
      scoring = 'neg_mean_absolute_error').mean() 
      # multiply by -1 to cross validation score to make positive MAE score 

predictors_wo_categoricals = train_predictors.select_dtypes(exclude = ['object'])

mae_wo_categoricals = get_mae(predictors_wo_categoricals, target)

mae_one_hot_encoded = get_mae(one_hot_encoded_training_predcitors, target)


print('Mean Absolute Error when Dropping Categoricals: ' + str(int(mae_wo_categoricals)))
print('Mean Abslute Error with One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))

